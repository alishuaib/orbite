Chapter 10: Ensemble Models in Knowledge Studio

Ensemble Models use multiple automatically grown decision trees to build a more comprehensive high performance predictive model. While they boast higher performance and automatic generation, the trees generated cannot be viewed and edited compared to the standalone decision tree node.

In this demonstration, we will explore Bagging, Random Forest and Boosting ensemble models.

To begin, let’s create a new workflow and link our Training dataset.

From the Model palette, let's drag each of the ensemble model nodes to the workflow canvas.

Next, connect the Training dataset to each node.

We need to configure the parameters for each ensemble model.

Double click “Bagging” to open the wizard.

Give the model an appropriate name and click “next.”

Select a dependent variable, in this case this will be Response.

Note that for Bagging and Random Forest, we can use any variable as the dependent, but for Boosting only binary variables can be used.

Next, select the independent variables to use in the model. We will select age, capital gain, education, hours per week, marital status, relationship and sex.

Click next to set parameters.

Under model growth, adjust the number of trees to generate. 250 trees is the default. Note that the more trees to generate, the longer the run time. For this demonstration, lets reduce this to 25 trees.

We can also adjust the sample size, lets use 50%.

The remaining parameters are the same as our decision tree node, we’ll keep the default settings.

After confirming everything is correct, click run.

Double click the model to review the parameter settings if needed. We will explore model performance later in this demo.

Next, double-click the Random Forest node to open the wizard.

Let’s use the same settings.

There is one additional parameter called “number of features.” We can adjust this to limit the number of independent variables used in each split - introducing variability in the trees which results in a more robust model.

Click “run” to generate the model.

Next, double-click on the Boosting node.

We will use the same settings again.

As you can see, we can only select binary dependent variables in boosting. Select Response and change the Target category to “Yes” before continuing.

Now that we have our models, let's connect them to a Model Validation node.

Let’s also connect our Training dataset.

Once the nodes turn blue, we can adjust the parameters.

For cut off values set 0.3 for yes and 0.7 for no.

Once we have the output for all 3 validation nodes, let's drag a Model Analyzer node from the evaluate palette to the canvas and connect each of the outputs generated.

Since we will be comparing the models, let's also bring in our previously generated interactive decision tree validation and connect it as well.

Once all 4 validation outputs are connected, double click to open the wizard.

For each tab, change the predicted value and probability score to "yes" and assign an appropriate name.

Click run.

Once the status changes to green, double click to view the analyzer results.

Now we can compare the performances for each model.

As we can see, all 3 ensemble models are out performing our interactive decision tree shown in the statistics and charts.

If we look at the ROC chart we can compare the AUC statistic for each model.

Ensemble models and the model analyzer node can help us develop more comprehensive models to achieve better performance.

